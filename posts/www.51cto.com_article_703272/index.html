<!doctype html><html lang=zh-cn dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>分布式 PostgreSQL之Citus 架构-postgresql 分布式 | MyNotes</title><meta name=keywords content="transaction,pg,citus"><meta name=description content="1 节点 1.1 Coordinator 与 Worker 2 分布式数据 2.1 表类型 2.2 Shards 3 查询执行 本文为摘录，原文为： https://www.51cto.com/article/703272.html 1 节点 Citus 是一种 PostgreSQL 扩展，它允许数据库服务器(称为节点)在“无共享(sha"><meta name=author content="Yang, Ying-chao"><link rel=canonical href=https://yangyingchao.github.io/posts/www.51cto.com_article_703272/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://yangyingchao.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://yangyingchao.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://yangyingchao.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://yangyingchao.github.io/apple-touch-icon.png><link rel=mask-icon href=https://yangyingchao.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="分布式 PostgreSQL之Citus 架构-postgresql 分布式"><meta property="og:description" content="1 节点 1.1 Coordinator 与 Worker 2 分布式数据 2.1 表类型 2.2 Shards 3 查询执行 本文为摘录，原文为： https://www.51cto.com/article/703272.html 1 节点 Citus 是一种 PostgreSQL 扩展，它允许数据库服务器(称为节点)在“无共享(sha"><meta property="og:type" content="article"><meta property="og:url" content="https://yangyingchao.github.io/posts/www.51cto.com_article_703272/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-05-13T00:00:00+00:00"><meta property="article:modified_time" content="2024-05-13T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="分布式 PostgreSQL之Citus 架构-postgresql 分布式"><meta name=twitter:description content="1 节点 1.1 Coordinator 与 Worker 2 分布式数据 2.1 表类型 2.2 Shards 3 查询执行 本文为摘录，原文为： https://www.51cto.com/article/703272.html 1 节点 Citus 是一种 PostgreSQL 扩展，它允许数据库服务器(称为节点)在“无共享(sha"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://yangyingchao.github.io/posts/"},{"@type":"ListItem","position":2,"name":"分布式 PostgreSQL之Citus 架构-postgresql 分布式","item":"https://yangyingchao.github.io/posts/www.51cto.com_article_703272/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"分布式 PostgreSQL之Citus 架构-postgresql 分布式","name":"分布式 PostgreSQL之Citus 架构-postgresql 分布式","description":"1 节点 1.1 Coordinator 与 Worker 2 分布式数据 2.1 表类型 2.2 Shards 3 查询执行 本文为摘录，原文为： https://www.51cto.com/article/703272.html 1 节点 Citus 是一种 PostgreSQL 扩展，它允许数据库服务器(称为节点)在“无共享(sha","keywords":["transaction","pg","citus"],"articleBody":" 1 节点 1.1 Coordinator 与 Worker 2 分布式数据 2.1 表类型 2.2 Shards 3 查询执行 本文为摘录，原文为： https://www.51cto.com/article/703272.html\n1 节点 Citus 是一种 PostgreSQL 扩展，它允许数据库服务器(称为节点)在“无共享(shared nothing)”架构中相互协调。这些节点形成一个集群， 允许 PostgreSQL 保存比单台计算机上更多的数据和使用更多的 CPU 内核。这种架构还允许通过简单地向集群添加更多节点来扩容数据 库。\n1.1 Coordinator 与 Worker 每个 cluster 都有一个称为 coordinator (协调器) 的特殊节点(其他节点称为 worker 节点)。\n应用程序将它们的查询发送到 coordinator 节点，\ncoordinator 节点将其转发给相关的 worker 并累积结果。\n对于每个查询，coordinator 根据所需数据是位于单个节点上还是多个节点上：\n要么将其路由到单个 worker 节点， 要么将其并行化到多个节点， coordinator 通过查阅其 元数据表 知道如何做到这一点\n这些 Citus 特定表跟踪 worker 节点的 DNS 名称和运行状况， 以及跨节点数据的分布情况。 2 分布式数据 2.1 表类型 Citus 集群中有三种类型的表，每种表都以不同方式存储在节点中，并且用于不同的目的：\n分布表 引用表 本地表 2.1.1 类型 1：分布式表 第一种类型，也是最常见的，是分布式表。对于 SQL 语句而言，它们看似是普通的表，但在 worker 节点之间 水平分区 。\n这里 table 的行存储在 worker 的表 table_1001 、 table_1002 等中。组件 worker 表称为分片(shards)。\n2.1.1.1 分布列 Citus 使用使用分片算法将行分配到分片。基于表列(称为 分布列 (distribution column))的值执行分配，此分配具有确定性。集群管理 员在分布表时必须指定此列。做出正确的选择，这一点对于性能和功能有重要影响。\n2.1.2 类型 2：引用表 （复制表） 引用表 是一种分布式表，其全部内容都集中到单个分片中，并在每个 worker 上复制。 对任何 worker 的查询都可以在本地访问引用信息，无需从另一个节点请求行，因此也不会产生此类网络开销。 引用表没有分布列，因为无需区分每行的各个分片。 引用表通常很小，用于存储与在任何工作节点上运行的查询相关的数据。 例如，订单状态或产品类别等枚举值。 当与 引用表 交互时，我们会自动对事务执行两阶段提交 (2PC)。这意味着 Citus 确保您的数据始终处于一致状态，无论您是在写入、修改还是删除它。\n2PC https://en.wikipedia.org/wiki/Two-phase_commit_protocol\n2.1.3 类型 3：本地表 当您使用 Citus 时，您连接并与之交互的 coordinator 节点是安装了 Citus 扩展的常规 PostgreSQL 数据库。因此，您可以创建普通 表并选择不对其进行分片。这对于不参与连接查询的小型管理表很有用。一个示例是用于应用程序登录和身份验证的用户表。\n创建标准 PostgreSQL 表很容易，因为它是默认值。这是你运行 CREATE TABLE 时得到的。在几乎每个 Citus 部署中，我们都会看到标准 PostgreSQL 表与 distributed 和 reference 表共存。事实上，如前所述，Citus 本身使用本地表来保存集群元数据。\n2.2 Shards 上一节将分片描述为在 worker 节点内的较小表中包含分布式表的行的子集。本节详细介绍了技术细节。\n协调器上的 pg_dist_shard 元数据表包含系统中每个分布式表的每个分片的行。该行与分片 ID 相匹配，分片 ID 的范围是一组哈希整数 (shardminvalue, shardmaxvalue) 。\nSELECT * from pg_dist_shard; logicalrelid | shardid | shardstorage | shardminvalue | shardmaxvalue ---------------+---------+--------------+---------------+--------------- github_events | 102026 | t | 268435456 | 402653183 github_events | 102027 | t | 402653184 | 536870911 github_events | 102028 | t | 536870912 | 671088639 github_events | 102029 | t | 671088640 | 805306367 (4 rows) 如果 coordinator 节点要确定哪个分片包含 github_events 行，它将对行中分布列的值执行哈希算法。然后此节点检查哪个分片的范围 包含此哈希值。定义范围后，哈希函数的 image(图像) 就是两者的并查。\n2.2.0.1 分片放置 假设分片 102027 与相应的行关联。在某个 worker 中的 github_events_102027 表中读取或写入此行。是哪个 worker?这完全由元数据 表确定。分片映射到 worker 的过程称为分片放置(shard placement)。\ncoordinator 节点将查询重写为引用特定表(例如 github_events_102027)的片段，并对相应 worker 运行这些片段。下面的查询示例在后 台运行，旨在查找分片 ID 为 102027 的节点。\nSELECT shardid, node.nodename, node.nodeport FROM pg_dist_placement placement JOIN pg_dist_node node ON placement.groupid = node.groupid AND node.noderole = 'primary'::noderole WHERE shardid = 102027; ┌─────────┬───────────┬──────────┐ │ shardid │ nodename │ nodeport │ ├─────────┼───────────┼──────────┤ │ 102027 │ localhost │ 5433 │ └─────────┴───────────┴──────────┘ 在 github_events 示例中，有四个分片。每个表的分片数量在其在集群中分布时是可配置的。\n最后请注意，Citus 允许复制分片以防止数据丢失。有两种复制“模式”：Citus 复制和流复制。前者创建额外的备份分片放置并针对所有 更新它们的所有它们运行查询。后者效率更高，利用 PostgreSQL 的流式复制将每个节点的整个数据库备份到一个 follower 数据库。这 是透明的，不需要 Citus 元数据表的参与。\n2.2.0.2 共置 由于可以根据需要将分片及其副本放置在节点上，因此将包含相关表的相关行的分片放在同一节点上是有意义的。这样，它们之间的连接 查询可以避免通过网络发送尽可能多的信息，并且可以在单个 Citus 节点内执行。\n一个示例是包含商店、产品和购买的数据库。如果所有三个表都包含 - 并且由 - store_id 列分布，那么限制在单个存储中的所有查询 都可以在单个工作节点上高效运行。即使查询涉及这些表的任意组合也是如此。\n2.2.0.3 并行性 跨多台机器分散查询允许一次运行更多查询，并允许通过向集群添加新机器来扩展处理速度。此外，如上一节所述，将单个查询拆分为片 段可以提高专用于它的处理能力。后一种情况实现了最大的并行性，这意味着 CPU 内核的利用率。\n读取或影响均匀分布在多个节点上的分片的查询能够以“实时”速度运行。请注意，查询的结果仍然需要通过协调器节点传回，因此当最终 结果紧凑时(例如计数和描述性统计等聚合函数)，加速效果最为明显。\n3 查询执行 在执行多分片查询时，Citus 必须平衡并行性的收益与数据库连接的开销(网络延迟和工作节点资源使用)。要配置 Citus 的查询执行以 获得最佳的数据库工作负载结果，它有助于了解 Citus 如何管理和保存协调节点和工作节点之间的数据库连接。\nCitus 将每个传入的多分片查询会话转换为称为任务的每个分片查询。它将任务排队，并在能够获得与相关工作节点的连接时运行它们。 对于分布式表 foo 和 bar 的查询，下面是连接管理图：\ncoordinator 节点为每个会话都有一个连接池。每个查询(例如图中的 SELECT * FROM foo)仅限于为每个 worker 的任务打开最多 citus.max_adaptive_executor_pool_size(整数)个同时连接。该设置可在会话级别进行配置，以进行优先级管理。\n在同一连接上按顺序执行短任务比为它们并行建立新连接更快。另一方面，长时间运行的任务受益于更直接的并行性。\n为了平衡短任务和长任务的需求，Citus 使用 citus.executor_slow_start_interval(整数)。该设置指定多分片查询中任务的连接尝试 之间的延迟。当查询首先对任务进行排队时，这些任务只能获取一个连接。在每个有待处理连接的时间间隔结束时，Citus 会增加它将打 开的同时连接数。通过将 GUC 设置为 0，可以完全禁用慢启动行为。\n当任务完成使用连接时，会话池将保持连接打开以供以后使用。缓存连接避免了 coordinator 和 worker 之间重新建立连接的开销。但是， 每个池一次打开的空闲连接不超过 citus.max_cached_conns_per_worker(整数)个，以限制 worker 中空闲连接资源的使用。\n最后，设置 citus.max_shared_pool_size (integer) 充当故障保险。它限制了所有任务之间每个 worker 的总连接数。\n","wordCount":"2802","inLanguage":"zh-cn","datePublished":"2024-05-13T00:00:00Z","dateModified":"2024-05-13T00:00:00Z","author":[{"@type":"Person","name":"Yang"},{"@type":"Person","name":"Ying-chao"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://yangyingchao.github.io/posts/www.51cto.com_article_703272/"},"publisher":{"@type":"Organization","name":"MyNotes","logo":{"@type":"ImageObject","url":"https://yangyingchao.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://yangyingchao.github.io accesskey=h title="MyNotes (Alt + H)">MyNotes</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://yangyingchao.github.io/ title=Home><span>Home</span></a></li><li><a href=https://yangyingchao.github.io/posts/ title=Archives><span>Archives</span></a></li><li><a href=https://yangyingchao.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://yangyingchao.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://yangyingchao.github.io/contact/ title="Contact me"><span>Contact me</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">分布式 PostgreSQL之Citus 架构-postgresql 分布式</h1><div class=post-meta><span title='2024-05-13 00:00:00 +0000 UTC'>May 13, 2024</span>&nbsp;·&nbsp;Yang, Ying-chao</div></header><div class=post-content><ul><li>1 <a href=#%E8%8A%82%E7%82%B9>节点</a><ul><li>1.1 <a href=#coordinator-%E4%B8%8E-worker>Coordinator 与 Worker</a></li></ul></li><li>2 <a href=#%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE>分布式数据</a><ul><li>2.1 <a href=#%E8%A1%A8%E7%B1%BB%E5%9E%8B>表类型</a></li><li>2.2 <a href=#shards>Shards</a></li></ul></li><li>3 <a href=#%E6%9F%A5%E8%AF%A2%E6%89%A7%E8%A1%8C>查询执行</a></li></ul><p>本文为摘录，原文为： <a href=https://www.51cto.com/article/703272.html>https://www.51cto.com/article/703272.html</a></p><h2 id=节点>1 节点<a hidden class=anchor aria-hidden=true href=#节点>#</a></h2><p>Citus 是一种 PostgreSQL 扩展，它允许数据库服务器(称为节点)在“无共享(shared nothing)”架构中相互协调。这些节点形成一个集群，
允许 PostgreSQL 保存比单台计算机上更多的数据和使用更多的 CPU 内核。这种架构还允许通过简单地向集群添加更多节点来扩容数据
库。</p><h3 id=coordinator-与-worker>1.1 Coordinator 与 Worker<a hidden class=anchor aria-hidden=true href=#coordinator-与-worker>#</a></h3><p>每个 cluster 都有一个称为 coordinator (协调器) 的特殊节点(其他节点称为 worker 节点)。</p><ul><li><p>应用程序将它们的查询发送到 coordinator 节点，</p></li><li><p>coordinator 节点将其转发给相关的 worker 并累积结果。</p></li><li><p>对于每个查询，coordinator 根据所需数据是位于单个节点上还是多个节点上：</p><ul><li>要么将其路由到单个 worker 节点，</li><li>要么将其并行化到多个节点，</li></ul></li><li><p>coordinator 通过查阅其 <strong>元数据表</strong> 知道如何做到这一点</p><ul><li>这些 Citus 特定表跟踪 worker 节点的 DNS 名称和运行状况， 以及跨节点数据的分布情况。</li></ul></li></ul><h2 id=分布式数据>2 分布式数据<a hidden class=anchor aria-hidden=true href=#分布式数据>#</a></h2><h3 id=表类型>2.1 表类型<a hidden class=anchor aria-hidden=true href=#表类型>#</a></h3><p>Citus 集群中有三种类型的表，每种表都以不同方式存储在节点中，并且用于不同的目的：</p><ul><li>分布表</li><li>引用表</li><li>本地表</li></ul><h4 id=类型-1-分布式表>2.1.1 类型 1：分布式表<a hidden class=anchor aria-hidden=true href=#类型-1-分布式表>#</a></h4><p>第一种类型，也是最常见的，是分布式表。对于 SQL 语句而言，它们看似是普通的表，但在 worker 节点之间 <strong>水平分区</strong> 。</p><figure><img loading=lazy src=/ox-hugo/911f207084d89908c1c242675bfbe2d047cf2e.png width=660px></figure><p>这里 table 的行存储在 worker 的表 <code>table_1001</code> 、 <code>table_1002</code> 等中。组件 worker 表称为分片(shards)。</p><h5 id=分布列>2.1.1.1 分布列<a hidden class=anchor aria-hidden=true href=#分布列>#</a></h5><p>Citus 使用使用分片算法将行分配到分片。基于表列(称为 <strong>分布列</strong> (distribution column))的值执行分配，此分配具有确定性。集群管理
员在分布表时必须指定此列。做出正确的选择，这一点对于性能和功能有重要影响。</p><h4 id=类型-2-引用表-复制表>2.1.2 类型 2：引用表 （复制表）<a hidden class=anchor aria-hidden=true href=#类型-2-引用表-复制表>#</a></h4><ul><li><strong>引用表</strong> 是一种分布式表，其全部内容都集中到单个分片中，并在每个 worker 上复制。</li><li>对任何 worker 的查询都可以在本地访问引用信息，无需从另一个节点请求行，因此也不会产生此类网络开销。</li><li>引用表没有分布列，因为无需区分每行的各个分片。</li><li>引用表通常很小，用于存储与在任何工作节点上运行的查询相关的数据。
例如，订单状态或产品类别等枚举值。</li></ul><p>当与 引用表 交互时，我们会自动对事务执行两阶段提交 (2PC)。这意味着 Citus 确保您的数据始终处于一致状态，无论您是在写入、修改还是删除它。</p><ul><li>2PC</li></ul><p><a href=https://en.wikipedia.org/wiki/Two-phase_commit_protocol>https://en.wikipedia.org/wiki/Two-phase_commit_protocol</a></p><h4 id=类型-3-本地表>2.1.3 类型 3：本地表<a hidden class=anchor aria-hidden=true href=#类型-3-本地表>#</a></h4><p>当您使用 Citus 时，您连接并与之交互的 coordinator 节点是安装了 Citus 扩展的常规 PostgreSQL 数据库。因此，您可以创建普通
表并选择不对其进行分片。这对于不参与连接查询的小型管理表很有用。一个示例是用于应用程序登录和身份验证的用户表。</p><p>创建标准 PostgreSQL 表很容易，因为它是默认值。这是你运行 CREATE TABLE 时得到的。在几乎每个 Citus 部署中，我们都会看到标准
PostgreSQL 表与 distributed 和 reference 表共存。事实上，如前所述，Citus 本身使用本地表来保存集群元数据。</p><h3 id=shards>2.2 Shards<a hidden class=anchor aria-hidden=true href=#shards>#</a></h3><p>上一节将分片描述为在 worker 节点内的较小表中包含分布式表的行的子集。本节详细介绍了技术细节。</p><p>协调器上的 <code>pg_dist_shard</code> 元数据表包含系统中每个分布式表的每个分片的行。该行与分片 ID 相匹配，分片 ID 的范围是一组哈希整数
<code>(shardminvalue, shardmaxvalue)</code> 。</p><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:green;font-weight:700>SELECT</span><span style=color:#bbb> </span><span style=color:#666>*</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>from</span><span style=color:#bbb> </span>pg_dist_shard;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span>logicalrelid<span style=color:#bbb>  </span><span style=color:#666>|</span><span style=color:#bbb> </span>shardid<span style=color:#bbb> </span><span style=color:#666>|</span><span style=color:#bbb> </span>shardstorage<span style=color:#bbb> </span><span style=color:#666>|</span><span style=color:#bbb> </span>shardminvalue<span style=color:#bbb> </span><span style=color:#666>|</span><span style=color:#bbb> </span>shardmaxvalue<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:#408080;font-style:italic>---------------+---------+--------------+---------------+---------------
</span></span></span><span style=display:flex><span><span style=color:#408080;font-style:italic></span><span style=color:#bbb> </span>github_events<span style=color:#bbb> </span><span style=color:#666>|</span><span style=color:#bbb>  </span><span style=color:#666>102026</span><span style=color:#bbb> </span><span style=color:#666>|</span><span style=color:#bbb> </span>t<span style=color:#bbb>            </span><span style=color:#666>|</span><span style=color:#bbb> </span><span style=color:#666>268435456</span><span style=color:#bbb>     </span><span style=color:#666>|</span><span style=color:#bbb> </span><span style=color:#666>402653183</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span>github_events<span style=color:#bbb> </span><span style=color:#666>|</span><span style=color:#bbb>  </span><span style=color:#666>102027</span><span style=color:#bbb> </span><span style=color:#666>|</span><span style=color:#bbb> </span>t<span style=color:#bbb>            </span><span style=color:#666>|</span><span style=color:#bbb> </span><span style=color:#666>402653184</span><span style=color:#bbb>     </span><span style=color:#666>|</span><span style=color:#bbb> </span><span style=color:#666>536870911</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span>github_events<span style=color:#bbb> </span><span style=color:#666>|</span><span style=color:#bbb>  </span><span style=color:#666>102028</span><span style=color:#bbb> </span><span style=color:#666>|</span><span style=color:#bbb> </span>t<span style=color:#bbb>            </span><span style=color:#666>|</span><span style=color:#bbb> </span><span style=color:#666>536870912</span><span style=color:#bbb>     </span><span style=color:#666>|</span><span style=color:#bbb> </span><span style=color:#666>671088639</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb> </span>github_events<span style=color:#bbb> </span><span style=color:#666>|</span><span style=color:#bbb>  </span><span style=color:#666>102029</span><span style=color:#bbb> </span><span style=color:#666>|</span><span style=color:#bbb> </span>t<span style=color:#bbb>            </span><span style=color:#666>|</span><span style=color:#bbb> </span><span style=color:#666>671088640</span><span style=color:#bbb>     </span><span style=color:#666>|</span><span style=color:#bbb> </span><span style=color:#666>805306367</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span>(<span style=color:#666>4</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>rows</span>)<span style=color:#bbb>
</span></span></span></code></pre></div><p>如果 coordinator 节点要确定哪个分片包含 <code>github_events</code> 行，它将对行中分布列的值执行哈希算法。然后此节点检查哪个分片的范围
包含此哈希值。定义范围后，哈希函数的 image(图像) 就是两者的并查。</p><h5 id=分片放置>2.2.0.1 分片放置<a hidden class=anchor aria-hidden=true href=#分片放置>#</a></h5><p>假设分片 102027 与相应的行关联。在某个 worker 中的 github_events_102027 表中读取或写入此行。是哪个 worker?这完全由元数据
表确定。分片映射到 worker 的过程称为分片放置(shard placement)。</p><p>coordinator 节点将查询重写为引用特定表(例如 github_events_102027)的片段，并对相应 worker 运行这些片段。下面的查询示例在后
台运行，旨在查找分片 ID 为 102027 的节点。</p><div class=highlight><pre tabindex=0 style=-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:green;font-weight:700>SELECT</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>shardid,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>node.nodename,<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb>    </span>node.nodeport<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>FROM</span><span style=color:#bbb> </span>pg_dist_placement<span style=color:#bbb> </span>placement<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>JOIN</span><span style=color:#bbb> </span>pg_dist_node<span style=color:#bbb> </span>node<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>ON</span><span style=color:#bbb> </span>placement.groupid<span style=color:#bbb> </span><span style=color:#666>=</span><span style=color:#bbb> </span>node.groupid<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>AND</span><span style=color:#bbb> </span>node.noderole<span style=color:#bbb> </span><span style=color:#666>=</span><span style=color:#bbb> </span><span style=color:#ba2121>&#39;primary&#39;</span>::noderole<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span style=color:green;font-weight:700>WHERE</span><span style=color:#bbb> </span>shardid<span style=color:#bbb> </span><span style=color:#666>=</span><span style=color:#bbb> </span><span style=color:#666>102027</span>;<span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span>┌─────────┬───────────┬──────────┐</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span>│</span><span style=color:#bbb> </span>shardid<span style=color:#bbb> </span><span>│</span><span style=color:#bbb> </span>nodename<span style=color:#bbb>  </span><span>│</span><span style=color:#bbb> </span>nodeport<span style=color:#bbb> </span><span>│</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span>├─────────┼───────────┼──────────┤</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span>│</span><span style=color:#bbb>  </span><span style=color:#666>102027</span><span style=color:#bbb> </span><span>│</span><span style=color:#bbb> </span>localhost<span style=color:#bbb> </span><span>│</span><span style=color:#bbb>     </span><span style=color:#666>5433</span><span style=color:#bbb> </span><span>│</span><span style=color:#bbb>
</span></span></span><span style=display:flex><span><span style=color:#bbb></span><span>└─────────┴───────────┴──────────┘</span><span style=color:#bbb>
</span></span></span></code></pre></div><p>在 github_events 示例中，有四个分片。每个表的分片数量在其在集群中分布时是可配置的。</p><p>最后请注意，Citus 允许复制分片以防止数据丢失。有两种复制“模式”：Citus 复制和流复制。前者创建额外的备份分片放置并针对所有
更新它们的所有它们运行查询。后者效率更高，利用 PostgreSQL 的流式复制将每个节点的整个数据库备份到一个 follower 数据库。这
是透明的，不需要 Citus 元数据表的参与。</p><h5 id=共置>2.2.0.2 共置<a hidden class=anchor aria-hidden=true href=#共置>#</a></h5><p>由于可以根据需要将分片及其副本放置在节点上，因此将包含相关表的相关行的分片放在同一节点上是有意义的。这样，它们之间的连接
查询可以避免通过网络发送尽可能多的信息，并且可以在单个 Citus 节点内执行。</p><p>一个示例是包含商店、产品和购买的数据库。如果所有三个表都包含 - 并且由 - store_id 列分布，那么限制在单个存储中的所有查询
都可以在单个工作节点上高效运行。即使查询涉及这些表的任意组合也是如此。</p><h5 id=并行性>2.2.0.3 并行性<a hidden class=anchor aria-hidden=true href=#并行性>#</a></h5><p>跨多台机器分散查询允许一次运行更多查询，并允许通过向集群添加新机器来扩展处理速度。此外，如上一节所述，将单个查询拆分为片
段可以提高专用于它的处理能力。后一种情况实现了最大的并行性，这意味着 CPU 内核的利用率。</p><p>读取或影响均匀分布在多个节点上的分片的查询能够以“实时”速度运行。请注意，查询的结果仍然需要通过协调器节点传回，因此当最终
结果紧凑时(例如计数和描述性统计等聚合函数)，加速效果最为明显。</p><h2 id=查询执行>3 查询执行<a hidden class=anchor aria-hidden=true href=#查询执行>#</a></h2><p>在执行多分片查询时，Citus 必须平衡并行性的收益与数据库连接的开销(网络延迟和工作节点资源使用)。要配置 Citus 的查询执行以
获得最佳的数据库工作负载结果，它有助于了解 Citus 如何管理和保存协调节点和工作节点之间的数据库连接。</p><p>Citus 将每个传入的多分片查询会话转换为称为任务的每个分片查询。它将任务排队，并在能够获得与相关工作节点的连接时运行它们。
对于分布式表 foo 和 bar 的查询，下面是连接管理图：</p><figure><img loading=lazy src=/ox-hugo/71549bc185ecdac0529037ad4fe9c6f95a7c7f.png width=800px></figure><p>coordinator 节点为每个会话都有一个连接池。每个查询(例如图中的 SELECT * FROM foo)仅限于为每个 worker 的任务打开最多
citus.max_adaptive_executor_pool_size(整数)个同时连接。该设置可在会话级别进行配置，以进行优先级管理。</p><p>在同一连接上按顺序执行短任务比为它们并行建立新连接更快。另一方面，长时间运行的任务受益于更直接的并行性。</p><p>为了平衡短任务和长任务的需求，Citus 使用 citus.executor_slow_start_interval(整数)。该设置指定多分片查询中任务的连接尝试
之间的延迟。当查询首先对任务进行排队时，这些任务只能获取一个连接。在每个有待处理连接的时间间隔结束时，Citus 会增加它将打
开的同时连接数。通过将 GUC 设置为 0，可以完全禁用慢启动行为。</p><p>当任务完成使用连接时，会话池将保持连接打开以供以后使用。缓存连接避免了 coordinator 和 worker 之间重新建立连接的开销。但是，
每个池一次打开的空闲连接不超过 citus.max_cached_conns_per_worker(整数)个，以限制 worker 中空闲连接资源的使用。</p><p>最后，设置 citus.max_shared_pool_size (integer) 充当故障保险。它限制了所有任务之间每个 worker 的总连接数。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://yangyingchao.github.io/tags/transaction/>transaction</a></li><li><a href=https://yangyingchao.github.io/tags/pg/>pg</a></li><li><a href=https://yangyingchao.github.io/tags/citus/>citus</a></li></ul></footer><script src=https://giscus.app/client.js data-repo=yangyingchao/giscus data-repo-id=R_kgDON6NYZA data-category=Announcements data-category-id=DIC_kwDON6NYZM4CnANs data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2025 <a href=https://yangyingchao.github.io>MyNotes</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>